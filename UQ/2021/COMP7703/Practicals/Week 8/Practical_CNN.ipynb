{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683a5b61",
   "metadata": {},
   "source": [
    "# COMP4702/7703 Prac 7: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "So, unless you're not at all interested in machine learning and AI (in which case why are you doing this course?!), you will have heard of convolutional neural networks. They are very high on the hype-curve because they have been very successful, amongst other things, at image processing. Here we will construct a small CNN to do classification on the MNIST dataset.\n",
    "\n",
    "The network follows this structure:\n",
    "\n",
    "[conv -> max_pool]*N -> FC -> FC\n",
    "\n",
    "where:\n",
    "* conv is a convolutional layer that applies a kernel to the previous layer\n",
    "* max_pool is a pooling layer\n",
    "* N is the number of conv-pool repititions \n",
    "* FC is a fully connected layer\n",
    "\n",
    "Again, the activation function is ReLU by default but feel free to change it! The number of filters in each convolutional layer is given by the layer number multiplied by the 'numFilters' variable defined in the code below; i.e. with 'numFilters' = 32, the first conv layer will have 32 filters, the second 64, the third 96, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d8e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\virtualenv\\ml\\tensorflow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from prac7ConvMLPModel import *\n",
    "from SupportCode.Helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d4dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTop = {}\n",
    "convTop['convPoolLayers'] = 1 # N\n",
    "# Convolutional layer parameters\n",
    "convTop['filterSize'] = 3 # F\n",
    "convTop['convStride'] = 1 # S\n",
    "# This is equivalent to the number of features\n",
    "convTop['numFilters'] = 32 # K\n",
    "# Pooling parameters\n",
    "convTop['poolK'] = 2 # F\n",
    "convTop['poolStride'] = 2 # S\n",
    "# Size of the first FC layer (Any ideas why we don't need to specify the size of the output layer? ;))\n",
    "convTop['FCLayerSize'] = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0042918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation dictionary for Gradient Descent\n",
    "optDicGD = {}\n",
    "optDicGD[\"optMethod\"] = \"GradientDescent\"\n",
    "optDicGD[\"learning_rate\"] = 0.0001\n",
    "\n",
    "activationFunction = tf.nn.relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8dfc9",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e45c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "[x_train, y_train], [x_test, y_test] = mnist\n",
    "\n",
    "# Flatten input arrays from 28x28 to 784 for x_train and x_test\n",
    "x_train = x_train.reshape(len(x_train), 784)\n",
    "x_test = x_test.reshape(len(x_test), 784)\n",
    "\n",
    "# Concatenate x_train and y_train in order to randomly shuffle whole dataset (VERY IMPORTANT - used for K-Fold CV)\n",
    "y_train = y_train.reshape(len(y_train), 1)\n",
    "train = np.concatenate((x_train, y_train), axis=1)\n",
    "np.random.shuffle(train)\n",
    "# Resplit x_train and y_train\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "\n",
    "# One hot encoding for y_train to be able to train neural net\n",
    "shape = (y_train.size, y_train.max() + 1)\n",
    "one_hot = np.zeros(shape)\n",
    "rows = np.arange(y_train.size)\n",
    "one_hot[rows, y_train] = 1\n",
    "y_train = one_hot\n",
    "\n",
    "# One hot encoding for y_train to be able to train neural net\n",
    "shape = (y_test.size, y_test.max() + 1)\n",
    "one_hot = np.zeros(shape)\n",
    "rows = np.arange(y_test.size)\n",
    "one_hot[rows, y_test] = 1\n",
    "y_test = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed645f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\virtualenv\\ml\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Accuracy at step 0: 0.1134\n",
      "Accuracy at step 10: 0.308\n",
      "Accuracy at step 20: 0.4579\n",
      "('Adding run metadata for', 24)\n",
      "Accuracy at step 30: 0.5247\n",
      "Accuracy at step 40: 0.5686\n",
      "('Adding run metadata for', 49)\n",
      "Accuracy at step 50: 0.5884\n",
      "Accuracy at step 60: 0.6214\n",
      "Accuracy at step 70: 0.6529\n",
      "('Adding run metadata for', 74)\n",
      "Accuracy at step 80: 0.6491\n",
      "Accuracy at step 90: 0.6661\n",
      "('Adding run metadata for', 99)\n",
      "('Accuracy on test set: ', 0.6778)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [x_train, y_train, x_test ,y_test]\n",
    "prac7ConvMLPModel(data, model='convNet', convTop=convTop, optimiser=optDicGD, act=activationFunction, max_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35134d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openTensorBoardAtIndex(\"convNet\", \"GradientDescent\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191ebd6",
   "metadata": {},
   "source": [
    "Have a look at the images of the convolutional weights in TensorBoard. Hopefully you find them interesting. [Here](http://cs231n.github.io/convolutional-networks/ ) is an excllent resource for more information on CNNs. Have a read of this material before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8a1ff",
   "metadata": {},
   "source": [
    "So you've implemented a CNN and that's pretty cool, but did you understand it?\n",
    "\n",
    "## Q2\n",
    "\n",
    "Using the link to the CS231n CNN theory given above, calculate the volume for the weight matrices of each layer for a convolutional network that has two conv-pool layers:\n",
    "\n",
    "\\[conv -> max_pool\\] (Layer 1) -> \\[conv -> max_pool\\] (Layer 2) -> FC -> FC\n",
    "\n",
    "Assume: \n",
    "* The input is 28x28.\n",
    "* Parameter sharing.\n",
    "* The number of filters in a particular layer is given by the expression: i*32, where i is the layer number.\n",
    "\n",
    "For the conv layer, assume:\n",
    "* A padding of 1 (P=1).\n",
    "* A stride length of 1.\n",
    "* A spatial extent of 3.\n",
    "\n",
    "For the pooling layer, assume:\n",
    "* A stride length of 1\n",
    "* A spatial extent of 2\n",
    "\n",
    "Assume that the first FC layer has 1024 neurons and the second has the number of classes in MNIST. \n",
    "\n",
    "Once you have done this calculate the number of parameters in this network.\n",
    "\n",
    "### Hint:\n",
    "Don't forget the biases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635f03e",
   "metadata": {},
   "source": [
    "### Set up variables (formulas used from CS231n CNN theory, also used this [link](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832a3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1*32\n",
    "P = 1\n",
    "S = 1\n",
    "F_conv = 3\n",
    "F_pool = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d1e1c",
   "metadata": {},
   "source": [
    "### Volume and number of parameters for each layer (total of 4 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c33536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in input layer: 0\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "num_input = 0\n",
    "print(f\"Number of parameters in input layer: {num_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84b2109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume for first conv layer: 25088.0\n",
      "Number of parameters in first conv layer: 896\n"
     ]
    }
   ],
   "source": [
    "# First conv layer\n",
    "W1 = 28\n",
    "H1 = 28\n",
    "D1 = 3\n",
    "\n",
    "W2 = (W1 - F_conv + 2*P)/S + 1\n",
    "H2 = W2\n",
    "D2 = K\n",
    "print(f\"Volume for first conv layer: {W2*H2* D2}\")\n",
    "\n",
    "num_conv1 = ((F_conv*F_conv*D1) + 1)*K\n",
    "print(f\"Number of parameters in first conv layer: {num_conv1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf55d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume for first pool layer: 23328.0\n",
      "Number of parameters in first pool layer: 0\n"
     ]
    }
   ],
   "source": [
    "# First pool layer\n",
    "W1 = W2\n",
    "H1 = H2\n",
    "D1 = D2\n",
    "\n",
    "W2 = (W1 - F_pool)/S + 1\n",
    "H2 = W2\n",
    "D2 = D1\n",
    "print(f\"Volume for first pool layer: {W2*H2* D2}\")\n",
    "\n",
    "num_pool1 = 0\n",
    "print(f\"Number of parameters in first pool layer: {num_pool1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98a48f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume for second conv layer: 46656.0\n",
      "Number of parameters in second conv layer: 18496\n"
     ]
    }
   ],
   "source": [
    "# Second conv layer\n",
    "W1 = W2\n",
    "H1 = H2\n",
    "D1 = D2\n",
    "\n",
    "W2 = (W1 - F_conv + 2*P)/S + 1\n",
    "H2 = W2\n",
    "K = 2*32\n",
    "D2 = K\n",
    "print(f\"Volume for second conv layer: {W2*H2* D2}\")\n",
    "\n",
    "num_conv2 = ((F_conv*F_conv*D1) + 1)*K\n",
    "print(f\"Number of parameters in second conv layer: {num_conv2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27f418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume for second pool layer: 43264.0\n",
      "Number of parameters in second pool layer: 0\n"
     ]
    }
   ],
   "source": [
    "# Second pool layer\n",
    "W1 = W2\n",
    "H1 = H2\n",
    "D1 = D2\n",
    "\n",
    "W2 = (W1 - F_pool)/S + 1\n",
    "H2 = W2\n",
    "D2 = D1\n",
    "print(f\"Volume for second pool layer: {W2*H2* D2}\")\n",
    "\n",
    "num_pool2 = 0\n",
    "print(f\"Number of parameters in second pool layer: {num_pool2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e2592f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume for first fully connected layer: 1024\n",
      "Number of parameters in first fully connected layer: 44303360.0\n"
     ]
    }
   ],
   "source": [
    "# First fully connected layer\n",
    "prev_layer = W2*H2*D2\n",
    "curr_layer = 1024\n",
    "print(f\"Volume for first fully connected layer: {curr_layer}\")\n",
    "\n",
    "\n",
    "num_fc1 = curr_layer*prev_layer + 1*curr_layer\n",
    "print(f\"Number of parameters in first fully connected layer: {num_fc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9e9a938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume for second fully connected layer: 10\n",
      "Number of parameters in second fully connected layer: 10250\n"
     ]
    }
   ],
   "source": [
    "# Second fully connected (output) layer\n",
    "prev_layer = curr_layer\n",
    "curr_layer = 10\n",
    "print(f\"Volume for second fully connected layer: {curr_layer}\")\n",
    "\n",
    "\n",
    "num_fc2 = curr_layer*prev_layer + 1*curr_layer\n",
    "print(f\"Number of parameters in second fully connected layer: {num_fc2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240cf66",
   "metadata": {},
   "source": [
    "### Total number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8caaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 44333002.0\n"
     ]
    }
   ],
   "source": [
    "total = num_input + num_conv1 + num_pool1 + num_conv2 + num_pool2 + num_fc1 + num_fc2\n",
    "print(f\"Total parameters: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcec4d6",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Calculate the number of parameters in an MLP that has two hidden layers, with 1000 neurons in the first hidden layer, and 300 neurons in the second hidden layer.\n",
    "\n",
    "Compare this number to the number of parameters that you calculated for the CNN in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ac96aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in first hidden layer: 2353000\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "prev_layer = 28*28*3\n",
    "curr_layer = 1000\n",
    "\n",
    "num_fc1 = curr_layer*prev_layer + 1*curr_layer\n",
    "print(f\"Number of parameters in first hidden layer: {num_fc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfeceb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in second hidden layer: 300300\n"
     ]
    }
   ],
   "source": [
    "# Second hidden layer\n",
    "prev_layer = curr_layer\n",
    "curr_layer = 300\n",
    "\n",
    "num_fc2 = curr_layer*prev_layer + 1*curr_layer\n",
    "print(f\"Number of parameters in second hidden layer: {num_fc2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02856a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in output layer: 3010\n"
     ]
    }
   ],
   "source": [
    "# Final output layer\n",
    "prev_layer = curr_layer\n",
    "curr_layer = 10\n",
    "\n",
    "num_fc3 = curr_layer*prev_layer + 1*curr_layer\n",
    "print(f\"Number of parameters in output layer: {num_fc3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e9fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2656310\n"
     ]
    }
   ],
   "source": [
    "total = num_fc1 + num_fc2 + num_fc3\n",
    "print(f\"Total parameters: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e6568",
   "metadata": {},
   "source": [
    "## Q4\n",
    "Compare the performance of the MLP and the CNN that you created. \n",
    "\n",
    "### Instructions:\n",
    "\n",
    "* Use a **table** to display your results and hyper-parameter choices.\n",
    "* Discuss the hyper-parameter selection of your CNN in **at most** 150 words.\n",
    "* Discuss the difference between the MLP and CNN in **at most** 100 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124dc8f",
   "metadata": {},
   "source": [
    "## Fun for Everyone \n",
    "\n",
    "So CNNs are super cool. They can make artwork like this:\n",
    "\n",
    "![inceptionism-neural-network-deep-dream-art-42__605.jpg](attachment:inceptionism-neural-network-deep-dream-art-42__605.jpg)\n",
    "\n",
    "Or they can make cool pictures like this:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "for maximum doge effect!\n",
    "\n",
    "Included in the assignment zip is the deep dream notebook (The second picture is generated from deep dream) that is available from the tensorflow tutorials. If you'd like feel free to go through the notebook and do some dreaming :)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
